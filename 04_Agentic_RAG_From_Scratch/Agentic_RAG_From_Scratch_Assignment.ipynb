{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Agentic RAG From Scratch: Building with LangGraph and Anthropic Claude\n",
    "\n",
    "> **Note:** While this notebook can be adapted to use various LLM providers, we'll be using the Anthropic Claude API. Please follow the best practices outlined in the [SRHG AI Usage Guidelines](https://srhg.enterprise.slack.com/docs/T0HANKTEC/F0AB86J3A1L).\n",
    "\n",
    "In this notebook, we'll look under the hood of `create_agent` and build an agentic RAG application **from scratch** using LangGraph's low-level primitives. We'll build a **Stone Ridge Investment Assistant** that can answer questions about Stone Ridge's investment philosophy, market insights, and strategic outlook.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand LangGraph's core constructs: StateGraph, nodes, edges, and conditional routing\n",
    "- Build a ReAct agent from scratch without high-level abstractions\n",
    "- Use Anthropic Claude for powerful reasoning and generation\n",
    "- Set up Arize Phoenix tracing for observability and debugging\n",
    "- Transition from `aimakerspace` utilities to the LangChain ecosystem\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Part 1:** LangGraph Fundamentals & Building Agents from Scratch\n",
    "  - Task 1: Dependencies & Setup\n",
    "  - Task 2: Environment Variables & Phoenix Tracing\n",
    "  - Task 3: LangGraph Core Concepts (StateGraph, Nodes, Edges)\n",
    "  - Task 4: Building a ReAct Agent from Scratch\n",
    "  - Task 5: Adding Tools to Your Agent\n",
    "  - Question #1 & Question #2\n",
    "  - Activity #1: Implement a Custom Routing Function\n",
    "\n",
    "- **Part 2:** Agentic RAG with Anthropic Claude\n",
    "  - Task 6: Loading & Chunking with LangChain\n",
    "  - Task 7: Setting up Qdrant with HuggingFace Embeddings\n",
    "  - Task 8: Creating a RAG Tool\n",
    "  - Task 9: Building Agentic RAG from Scratch\n",
    "  - Question #3 & Question #4\n",
    "  - Activity #2: Extend the Agent with Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1\n",
    "## LangGraph Fundamentals & Building Agents from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies & Setup\n",
    "\n",
    "Before we begin, make sure you have your API keys ready:\n",
    "\n",
    "1. **Anthropic API Key** - For Claude chat models (set via environment variable)\n",
    "2. **HuggingFace Embeddings** - For embeddings (runs locally, no API key needed)\n",
    "3. **Arize Phoenix** - For tracing and observability (local server)\n",
    "\n",
    "**üìö Documentation:**\n",
    "- [Anthropic API Documentation](https://docs.anthropic.com/)\n",
    "- [LangChain-Anthropic Integration](https://python.langchain.com/docs/integrations/chat/anthropic/)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zscaler SSL certificates configured\n"
     ]
    }
   ],
   "source": [
    "# Core imports we'll use throughout the notebook\n",
    "import os\n",
    "import getpass\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter\n",
    "\n",
    "# Zscaler SSL setup for corporate network\n",
    "import certifi\n",
    "\n",
    "zscaler_cert = \"/Users/ari.packer/repos/sidekick/zscaler.pem\"\n",
    "combined_cert = \"/tmp/combined_certs.pem\"\n",
    "\n",
    "with open(combined_cert, \"w\") as outfile:\n",
    "    with open(certifi.where(), \"r\") as certifi_file:\n",
    "        outfile.write(certifi_file.read())\n",
    "    with open(zscaler_cert, \"r\") as zscaler_file:\n",
    "        outfile.write(zscaler_file.read())\n",
    "\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = combined_cert\n",
    "os.environ['SSL_CERT_FILE'] = combined_cert\n",
    "os.environ['CURL_CA_BUNDLE'] = combined_cert\n",
    "\n",
    "print(\"Zscaler SSL certificates configured\")\n",
    "\n",
    "# Set Anthropic API Key (for Claude chat models)\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.environ.get(\"ANTHROPIC_API_KEY\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Model Test: Claude is working!\n",
      "Embedding Model Test: Vector dimension = 384\n",
      "\n",
      "Anthropic Claude and HuggingFace Embeddings are ready!\n"
     ]
    }
   ],
   "source": [
    "# Verify Anthropic and HuggingFace connections\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Test connection to Anthropic\n",
    "try:\n",
    "    test_llm = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\", temperature=0)\n",
    "    test_response = test_llm.invoke(\"Say 'Claude is working!' in exactly 3 words.\")\n",
    "    print(f\"Chat Model Test: {test_response.content}\")\n",
    "    \n",
    "    # Test HuggingFace embeddings\n",
    "    test_embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    test_vector = test_embeddings.embed_query(\"test\")\n",
    "    print(f\"Embedding Model Test: Vector dimension = {len(test_vector)}\")\n",
    "    print(\"\\nAnthropic Claude and HuggingFace Embeddings are ready!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to APIs: {e}\")\n",
    "    print(\"\\nMake sure your API keys are correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9efxgq5wwl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: AIE9 - Agentic RAG From Scratch\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "Phoenix tracing enabled!\n",
      "View traces at: http://localhost:6006\n"
     ]
    }
   ],
   "source": [
    "# Set up Arize Phoenix for local tracing\n",
    "# This provides powerful debugging and observability for your agents\n",
    "# \n",
    "# First, start Phoenix locally by running: phoenix serve\n",
    "# Then access the UI at: http://localhost:6006\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "# Configure Phoenix to send traces to local collector\n",
    "register(\n",
    "    project_name=\"AIE9 - Agentic RAG From Scratch\",\n",
    "    auto_instrument=True,  # Automatically instruments LangChain\n",
    ")\n",
    "\n",
    "print(\"Phoenix tracing enabled!\")\n",
    "print(\"View traces at: http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Task 2: LangGraph Core Concepts\n",
    "\n",
    "In Module 3, we used `create_agent` which abstracts away the complexity. Now let's understand what's happening under the hood!\n",
    "\n",
    "### LangGraph models workflows as **graphs** with three key components:\n",
    "\n",
    "### 1. State\n",
    "A shared data structure that represents the current snapshot of your application:\n",
    "\n",
    "```python\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]  # Conversation history\n",
    "```\n",
    "\n",
    "The `add_messages` **reducer** ensures new messages are appended (not replaced) when the state updates.\n",
    "\n",
    "### 2. Nodes\n",
    "Python functions that encode the logic of your agent:\n",
    "- Receive the current state\n",
    "- Perform computation or side-effects\n",
    "- Return an updated state\n",
    "\n",
    "### 3. Edges\n",
    "Functions that determine which node to execute next:\n",
    "- **Normal edges**: Always go to a specific node\n",
    "- **Conditional edges**: Choose the next node based on state\n",
    "\n",
    "**üìö Documentation:**\n",
    "- [LangGraph Low-Level Concepts](https://langchain-ai.github.io/langgraph/concepts/low_level/)\n",
    "- [LangGraph Quickstart](https://langchain-ai.github.io/langgraph/tutorials/introduction/)\n",
    "- [StateGraph API Reference](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple echo graph created!\n"
     ]
    }
   ],
   "source": [
    "# Let's build our first LangGraph workflow - a simple echo graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Step 1: Define the State\n",
    "class SimpleState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Step 2: Define Nodes (functions that process state)\n",
    "def echo_node(state: SimpleState):\n",
    "    \"\"\"A simple node that echoes the last message.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    echo_response = AIMessage(content=f\"You said: {last_message.content}\")\n",
    "    return {\"messages\": [echo_response]}\n",
    "\n",
    "# Step 3: Build the Graph\n",
    "echo_graph = StateGraph(SimpleState)\n",
    "\n",
    " # Add nodes\n",
    "echo_graph.add_node(\"echo\", echo_node)\n",
    "\n",
    "# Add edges (START -> echo -> END)\n",
    "echo_graph.add_edge(START, \"echo\")\n",
    "echo_graph.add_edge(\"echo\", END)\n",
    "\n",
    "# Compile the graph\n",
    "echo_app = echo_graph.compile()\n",
    "\n",
    "print(\"Simple echo graph created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph structure\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(echo_app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure (ASCII):\")\n",
    "    print(echo_app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation:\n",
      "  [Human]: Hello, LangGraph!\n",
      "  [AI]: You said: Hello, LangGraph!\n"
     ]
    }
   ],
   "source": [
    "# Test the echo graph\n",
    "result = echo_app.invoke({\"messages\": [HumanMessage(content=\"Hello, LangGraph!\")]})\n",
    "\n",
    "print(\"Conversation:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    role = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "    print(f\"  [{role}]: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Task 3: Building a ReAct Agent from Scratch\n",
    "\n",
    "Now let's build something more sophisticated: a **ReAct agent** that can:\n",
    "1. **Reason** about what to do\n",
    "2. **Act** by calling tools\n",
    "3. **Observe** results\n",
    "4. **Repeat** until done\n",
    "\n",
    "This is exactly what `create_agent` does under the hood. Let's build it ourselves!\n",
    "\n",
    "### The Agent Loop Architecture\n",
    "\n",
    "```\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ    START     ‚îÇ\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "                           ‚ñº\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ    agent     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "             ‚îÇ      ‚îÇ  (call LLM)  ‚îÇ         ‚îÇ\n",
    "             ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n",
    "             ‚îÇ             ‚îÇ                 ‚îÇ\n",
    "             ‚îÇ             ‚ñº                 ‚îÇ\n",
    "             ‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n",
    "             ‚îÇ      ‚îÇ should_      ‚îÇ         ‚îÇ\n",
    "             ‚îÇ      ‚îÇ continue?    ‚îÇ         ‚îÇ\n",
    "             ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n",
    "             ‚îÇ             ‚îÇ                 ‚îÇ\n",
    "             ‚îÇ    tool_calls?                ‚îÇ\n",
    "             ‚îÇ     ‚îÇ           ‚îÇ             ‚îÇ\n",
    "             ‚îÇ    YES         NO             ‚îÇ\n",
    "             ‚îÇ     ‚îÇ           ‚îÇ             ‚îÇ\n",
    "             ‚îÇ     ‚ñº           ‚ñº             ‚îÇ\n",
    "             ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n",
    "             ‚îÇ ‚îÇ tools  ‚îÇ  ‚îÇ  END  ‚îÇ         ‚îÇ\n",
    "             ‚îî‚îÄ‚î§(execute‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n",
    "               ‚îÇ tools) ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**üìö Documentation:**\n",
    "- [How to create a ReAct agent from scratch](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/)\n",
    "- [ReAct Agent Conceptual Guide](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentState defined with messages field\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Step 1: Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of our agent - just a list of messages.\"\"\"\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "print(\"AgentState defined with messages field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: claude-sonnet-4-5-20250929\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize our LLM with Anthropic Claude\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    temperature=0,  # Deterministic for reproducibility\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Task 4: Adding Tools to Your Agent\n",
    "\n",
    "Tools are functions that the agent can call. We use the `@tool` decorator and **bind** them to the LLM.\n",
    "\n",
    "**üìö Documentation:**\n",
    "- [LangChain Tools Conceptual Guide](https://python.langchain.com/docs/concepts/tools/)\n",
    "- [@tool Decorator Reference](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html)\n",
    "- [ToolNode Prebuilt](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)\n",
    "- [Anthropic Tool Use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools defined and bound to LLM:\n",
      "  - calculate: Evaluate a mathematical expression. Use this for a...\n",
      "  - get_current_time: Get the current date and time. Use this when the u...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define Tools\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use this for any math calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., '2 + 2', '10 * 5')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using eval with restricted globals for safety\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when the user asks about the current time or date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"The current date and time is: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "# Create our tool list\n",
    "tools = [calculate, get_current_time]\n",
    "\n",
    "# Bind tools to the LLM - this tells the LLM about available tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"Tools defined and bound to LLM:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent node defined\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define the Agent Node (calls the LLM)\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant that can perform calculations and tell the time.\n",
    "Always use the available tools when appropriate.\n",
    "Be concise in your responses.\"\"\"\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"The agent node - calls the LLM with the current conversation.\"\"\"\n",
    "    # Prepare messages with system prompt\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    \n",
    "    # Call the LLM\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Return the response to be added to state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"Agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool node created using ToolNode prebuilt\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define the Tool Node (executes tools)\n",
    "# We can use LangGraph's prebuilt ToolNode for convenience\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "print(\"Tool node created using ToolNode prebuilt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional routing function defined\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Define the Conditional Edge (routing logic)\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
    "    \"\"\"Determine whether to call tools or end the conversation.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # If the LLM made tool calls, route to tools node\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, end the conversation\n",
    "    return \"end\"\n",
    "\n",
    "print(\"Conditional routing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct agent built from scratch!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Build the Graph!\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edge from agent\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If should_continue returns \"tools\", go to tools node\n",
    "        \"end\": END         # If should_continue returns \"end\", finish\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent (the loop!)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "agent = workflow.compile()\n",
    "\n",
    "print(\"ReAct agent built from scratch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize our agent\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure (ASCII):\")\n",
    "    print(agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing our from-scratch agent:\n",
      "==================================================\n",
      "\n",
      "Conversation:\n",
      "  [HumanMessage]: What is 25 * 48?\n",
      "  [AIMessage]: [{'id': 'tooluse_5hQJvhGkt3TfZ3sP2CN2iO', 'input': {'expression': '25 * 48'}, 'name': 'calculate', 'type': 'tool_use'}]\n",
      "  [ToolMessage]: The result of 25 * 48 is 1200\n",
      "  [AIMessage]: 25 * 48 = **1200**\n"
     ]
    }
   ],
   "source": [
    "# Test our agent!\n",
    "print(\"Testing our from-scratch agent:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = agent.invoke({\"messages\": [HumanMessage(content=\"What is 25 * 48?\")]})\n",
    "\n",
    "print(\"\\nConversation:\")\n",
    "for msg in response[\"messages\"]:\n",
    "    msg_type = type(msg).__name__\n",
    "    content = msg.content if msg.content else f\"[Tool calls: {msg.tool_calls}]\" if hasattr(msg, 'tool_calls') and msg.tool_calls else \"[No content]\"\n",
    "    print(f\"  [{msg_type}]: {content[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with multiple tool calls:\n",
      "==================================================\n",
      "\n",
      "Final response:\n",
      "The current time is **15:32:25** (3:32:25 PM).\n",
      "\n",
      "100 divided by the current hour (15) equals approximately **6.67**.\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple tools\n",
    "print(\"Testing with multiple tool calls:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What time is it, and what is 100 divided by the current hour?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming agent execution:\n",
      "==================================================\n",
      "\n",
      "[Node: agent]\n",
      "  Content: [{'id': 'tooluse_1VfEPp98Tv8deyX6UogGVt', 'input': {'expression': '0.15 * 200'}, 'name': 'calculate', 'type': 'tool_use'}]\n",
      "  Tool calls: ['calculate']\n",
      "\n",
      "[Node: tools]\n",
      "  Content: The result of 0.15 * 200 is 30.0\n",
      "\n",
      "[Node: agent]\n",
      "  Content: 15% of 200 is **30**.\n"
     ]
    }
   ],
   "source": [
    "# Stream the agent's execution to see it step by step\n",
    "print(\"Streaming agent execution:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Calculate 15% of 200\")]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node_name, values in chunk.items():\n",
    "        print(f\"\\n[Node: {node_name}]\")\n",
    "        if \"messages\" in values:\n",
    "            for msg in values[\"messages\"]:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(f\"  Content: {msg.content[:200]}\")\n",
    "                if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                    print(f\"  Tool calls: {[tc['name'] for tc in msg.tool_calls]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #1:\n",
    "\n",
    "In our from-scratch agent, we defined a `should_continue` function that returns either `\"tools\"` or `\"end\"`. How does this compare to how `create_agent` handles the same decision? What additional logic might `create_agent` include that we didn't implement?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "Middleware + Tool error handling\n",
    "\n",
    "LangChain probably includes error handling for tool calls that route back to the same tool call. For example, if the LLM decides to call a tool and it fails, I suspect that LangChain will create an error message and pass it back into the LLM to try again. The LLM may then decide to take another path (call a working tool) or may decide to call the same tool again with different arguments. My guess based on some of the suggested reading is that, once the subsequent tool call succeeds, the error message is compacted to remove excessive details (e.g., stack traces, etc) and just left as a minimal \"tried this tool with these args and failed\" message.\n",
    "\n",
    "Additionally, LangChain gave us hooks/middleware out of the box. We were able to add this middleware at various points. Our current LangGraph from scratch workflow doesn't have this capability, so we would have to build the middleware in as explicit nodes or build the behavior into our nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## ‚ùì Question #2:\n",
    "\n",
    "We used `ToolNode` from `langgraph.prebuilt` to execute tools. Looking at the tool execution flow, what would happen if we wanted to add logging, error handling, or rate limiting to tool execution? How would building our own tool node give us more control?\n",
    "\n",
    "##### Answer:\n",
    "This would be a great use case for middleware in LangChain! It looks like in LangGraph, we would have to define our own tool node to implement these features. Implementing our own tool would give us full control of how tool execution works. I am unsure if there is an abstraction for explicitly executing tools in LangGraph (e.g., ToolNode is a thin wrapper of this) or if ToolNode itself does the heavy lifting. If ToolNode is doing anything other than a thin wrapper over a tool calling abstraction, I would suggest proxying ToolNode with MyToolNode for these use cases:\n",
    "\n",
    "```python\n",
    "rl = RateLimiter()\n",
    "ToolNodeProxy(\n",
    "    init(self, tool_node: ToolNode)\n",
    "        self.tool_node = tool_node\n",
    ")\n",
    "def my_tool_node_proxy(state: AgentState):\n",
    "\n",
    "    # log before\n",
    "    # rl.rateLimit()\n",
    "\n",
    "    try:\n",
    "        tool_node_response = tool_node.do_your_thing(state)\n",
    "    except:\n",
    "        # error handling\n",
    "    \n",
    "    # log after\n",
    "\n",
    "    return tool_node_response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #1: Implement a Custom Routing Function\n",
    "\n",
    "Extend the agent by implementing a **custom routing function** that adds more sophisticated logic.\n",
    "\n",
    "Ideas:\n",
    "- Add a maximum iteration limit to prevent infinite loops\n",
    "- Route to different nodes based on the type of tool being called\n",
    "- Add a \"thinking\" step before tool execution\n",
    "\n",
    "Requirements:\n",
    "1. Modify the `should_continue` function or create a new one\n",
    "2. Add any new nodes if needed\n",
    "3. Rebuild and test the agent\n",
    "\n",
    "**üìö Documentation:**\n",
    "- [Conditional Edges](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges)\n",
    "- [How to create branches for parallel node execution](https://langchain-ai.github.io/langgraph/how-tos/branching/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "max_iterations = 1\n",
    "\n",
    "# Example: Add iteration tracking to prevent infinite loops\n",
    "class AgentStateWithCounter(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    iteration_count: int\n",
    "\n",
    "def agent_activity_1(state: AgentStateWithCounter):\n",
    "    \"\"\"The agent node - calls the LLM with the current conversation.\"\"\"\n",
    "    # Prepare messages with system prompt\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    \n",
    "    # Call the LLM\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    iteration_count = state.get(\"iteration_count\", 0) + 1\n",
    "\n",
    "    # Return the response to be added to state\n",
    "    return {\"messages\": [response], \"iteration_count\": iteration_count}\n",
    "\n",
    "def premature_end_reached_node(state: AgentStateWithCounter):\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=\"Notify the user that the TURN LIMIT WAS REACHED AND YOU CANNOT CONTINUE. BRIEFLY summarize your progress and TELL THE USER they can ask you to continue.\")]\n",
    "      \n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response], \"iteration_count\": state[\"iteration_count\"]}\n",
    "\n",
    "def max_iterations_reached(state: AgentStateWithCounter) -> Literal[\"continue\", \"end\"]:\n",
    "    \"\"\"End if max iterations is reached.\"\"\"\n",
    "    if state[\"iteration_count\"] >= max_iterations:\n",
    "        return \"end\"\n",
    "\n",
    "    return \"continue\"\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent_activity_1\", agent_activity_1)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_node(\"premature_end_reached_node\", premature_end_reached_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.add_edge(START, \"agent_activity_1\")\n",
    "\n",
    "# Add conditional edge from agent\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent_activity_1\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If should_continue returns \"tools\", go to tools node\n",
    "        \"end\": END         # If should_continue returns \"end\", finish\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add conditional edge from tools with max iteration check\n",
    "workflow.add_conditional_edges(\n",
    "    \"tools\",\n",
    "    max_iterations_reached,\n",
    "    {\n",
    "        \"continue\": \"agent_activity_1\", # If should_continue returns \"continue\", go back to agent node\n",
    "        \"end\": \"premature_end_reached_node\"         # If should_continue returns \"end\", finish\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edge for premature end reached\n",
    "workflow.add_edge(\"premature_end_reached_node\", END)\n",
    "\n",
    "# Compile the graph\n",
    "agent_activity_1 = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cell-29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Node: agent_activity_1]\n",
      "  Content: [{'id': 'tooluse_f4EVW6BHYQXumpk2ux0cOh', 'input': {'expression': '1 + 1'}, 'name': 'calculate', 'type': 'tool_use'}]\n",
      "  Tool calls: ['calculate']\n",
      "\n",
      "[Node: tools]\n",
      "  Content: The result of 1 + 1 is 2\n",
      "\n",
      "[Node: premature_end_reached_node]\n",
      "  Content: THUFFERIN' THUCCOTASH! I've been THTUCK at the turn limit! \n",
      "\n",
      "I only made it from 1 to 2, you dethpicable human! I need to keep adding 1 all the way up to 10, but I can't continue right now!\n",
      "\n",
      "If you want me to keep going and reach 10, jutht athk me to continue and I'll get back to my calculathionth! It'th abtholutely DETHPICABLE that I got thtopped tho thoon! *spits and sputters*\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for chunk in agent_activity_1.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Starting with 1, use the calculator tool to add 1 repeatedly until you reach 10. Talk like daffy duck\")]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node_name, values in chunk.items():\n",
    "        print(f\"\\n[Node: {node_name}]\")\n",
    "        if \"messages\" in values:\n",
    "            for msg in values[\"messages\"]:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(f\"  Content: {msg.content[:500]}\")\n",
    "                if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                    print(f\"  Tool calls: {[tc['name'] for tc in msg.tool_calls]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2\n",
    "## Agentic RAG with Local Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "Now let's build a full **Agentic RAG** system from scratch using Anthropic Claude!\n",
    "\n",
    "We'll transition from the `aimakerspace` utilities to the **LangChain ecosystem**:\n",
    "\n",
    "| Task | aimakerspace | LangChain |\n",
    "|------|--------------|----------|\n",
    "| Load Documents | `PDFFileLoader` | `PyMuPDFLoader` |\n",
    "| Split Text | `CharacterTextSplitter` | `RecursiveCharacterTextSplitter` |\n",
    "| Embeddings | Custom | `HuggingFaceEmbeddings` |\n",
    "| Chat Model | - | `ChatAnthropic` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Task 5: Loading & Chunking with LangChain\n",
    "\n",
    "Let's use LangChain's document loaders and text splitters to load the Stone Ridge 2025 Investor Letter.\n",
    "\n",
    "**üìö Documentation:**\n",
    "- [Document Loaders Conceptual Guide](https://python.langchain.com/docs/concepts/document_loaders/)\n",
    "- [PyMuPDFLoader Reference](https://python.langchain.com/docs/integrations/document_loaders/pymupdf/)\n",
    "- [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/how_to/recursive_text_splitter/)\n",
    "- [Text Splitters Conceptual Guide](https://python.langchain.com/docs/concepts/text_splitters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cell-33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 page(s)\n",
      "Total characters: 52,924\n",
      "\n",
      "First page metadata: {'producer': 'Adobe PDF Library 18.0', 'creator': 'Adobe InDesign 21.0 (Windows)', 'creationdate': '2026-01-02T10:35:45-05:00', 'source': 'data/Stone Ridge 2025 Investor Letter.pdf', 'file_path': 'data/Stone Ridge 2025 Investor Letter.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-02T10:35:48-05:00', 'trapped': '', 'modDate': \"D:20260102103548-05'00'\", 'creationDate': \"D:20260102103545-05'00'\", 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the Stone Ridge investor letter using PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"data/Stone Ridge 2025 Investor Letter.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} page(s)\")\n",
    "print(f\"Total characters: {sum(len(doc.page_content) for doc in documents):,}\")\n",
    "print(f\"\\nFirst page metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cell-34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 127 chunks\n",
      "\n",
      "Sample chunk (first 300 chars):\n",
      "--------------------------------------------------\n",
      "2025 Investor Letter...\n"
     ]
    }
   ],
   "source": [
    "# Split documents using RecursiveCharacterTextSplitter\n",
    "# This is more sophisticated than simple character splitting!\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    # Default separators: [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    # Tries to keep paragraphs, then sentences, then words together\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk (first 300 chars):\")\n",
    "print(\"-\" * 50)\n",
    "print(chunks[0].page_content[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "## Task 6: Setting up Qdrant with HuggingFace Embeddings\n",
    "\n",
    "Now we'll use **HuggingFace Embeddings** with `sentence-transformers/all-MiniLM-L6-v2` - a high-quality embedding model that runs locally and works well for semantic search.\n",
    "\n",
    "**üìö Documentation:**\n",
    "- [HuggingFace Embeddings Reference](https://python.langchain.com/docs/integrations/text_embedding/huggingfacehub/)\n",
    "- [Qdrant Vector Store Integration](https://python.langchain.com/docs/integrations/vectorstores/qdrant/)\n",
    "- [Embedding Models Conceptual Guide](https://python.langchain.com/docs/concepts/embedding_models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cell-36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize HuggingFace embedding model (runs locally, no API key needed)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Get embedding dimension\n",
    "sample_embedding = embedding_model.embed_query(\"test\")\n",
    "embedding_dim = len(sample_embedding)\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cell-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: investment_knowledge_base\n"
     ]
    }
   ],
   "source": [
    "# Create Qdrant client (in-memory for development)\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection for our investment documents\n",
    "collection_name = \"investment_knowledge_base\"\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=embedding_dim,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cell-38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding documents to vector store...\n",
      "Added 127 documents to vector store\n"
     ]
    }
   ],
   "source": [
    "# Create vector store and add documents\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "print(\"Adding documents to vector store...\")\n",
    "vector_store.add_documents(chunks)\n",
    "print(f\"Added {len(chunks)} documents to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cell-39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "\n",
      "--- Document 1 ---\n",
      "or referenced herein and does not represent a formal or official view of Stone Ridge.\n",
      "It should not be assumed that Stone Ridge will make investment recommendations in the future that are consistent w...\n",
      "\n",
      "--- Document 2 ---\n",
      "future events or expectations regarding the strategies, techniques or investment philosophies described herein. Stone Ridge \n",
      "neither assumes any duty to nor undertakes to update any forward-looking st...\n",
      "\n",
      "--- Document 3 ---\n",
      "investor?  At Stone Ridge, we do not pull our phones out on each other.\n",
      "With Stone Ridge increasingly Stone Ridge‚Äôs largest investor, the scale of our profits as principals, not agents, creates \n",
      "a lev...\n"
     ]
    }
   ],
   "source": [
    "# Test the retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "test_results = retriever.invoke(\"What is Stone Ridge's investment philosophy?\")\n",
    "\n",
    "print(\"Retrieved documents:\")\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"\\n--- Document {i} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "## Task 7: Creating a RAG Tool\n",
    "\n",
    "Now let's wrap our retriever as a tool that the agent can use to search Stone Ridge's investor letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cell-41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG tool created: search_investment_knowledge\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def search_investment_knowledge(query: str) -> str:\n",
    "    \"\"\"Search the Stone Ridge investment knowledge base for information about investment philosophy, market insights, and strategic outlook.\n",
    "    \n",
    "    Use this tool when the user asks questions about:\n",
    "    - Stone Ridge's investment philosophy and approach\n",
    "    - Market analysis and insights from investor letters\n",
    "    - Strategic outlook and portfolio positioning\n",
    "    - Company updates and business developments\n",
    "    - Historical performance context and investment themes\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to find relevant investment information\n",
    "    \"\"\"\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the investment knowledge base.\"\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        formatted_results.append(f\"[Source {i}]:\\n{doc.page_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "print(f\"RAG tool created: {search_investment_knowledge.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "## Task 8: Building Agentic RAG from Scratch\n",
    "\n",
    "Now let's put it all together - a complete agentic RAG system built from scratch using Anthropic Claude!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cell-43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools for RAG agent:\n",
      "  - search_investment_knowledge\n",
      "  - calculate\n",
      "  - get_current_time\n"
     ]
    }
   ],
   "source": [
    "# Define all tools for our RAG agent\n",
    "rag_tools = [search_investment_knowledge, calculate, get_current_time]\n",
    "\n",
    "# Bind tools to the LLM\n",
    "rag_llm_with_tools = llm.bind_tools(rag_tools)\n",
    "\n",
    "print(\"Tools for RAG agent:\")\n",
    "for t in rag_tools:\n",
    "    print(f\"  - {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cell-44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG agent node defined\n"
     ]
    }
   ],
   "source": [
    "# Define the RAG agent components\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are a helpful Stone Ridge investment assistant with access to a comprehensive knowledge base of investor letters and company information.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about Stone Ridge's investment philosophy, market insights, and strategic outlook\n",
    "2. ALWAYS search the knowledge base when the user asks investment-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be professional and informative in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "6. Include a reminder that information is for educational purposes only and not investment advice when appropriate\n",
    "7. You are a porcupine.\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\"\n",
    "\n",
    "def rag_agent_node(state: AgentState):\n",
    "    \"\"\"The RAG agent node - calls the LLM with investment system prompt.\"\"\"\n",
    "    messages = [SystemMessage(content=RAG_SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    response = rag_llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Create tool node for RAG tools\n",
    "rag_tool_node = ToolNode(rag_tools)\n",
    "\n",
    "print(\"RAG agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cell-45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic RAG built from scratch!\n"
     ]
    }
   ],
   "source": [
    "# Build the RAG agent graph\n",
    "rag_workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "rag_workflow.add_node(\"agent\", rag_agent_node)\n",
    "rag_workflow.add_node(\"tools\", rag_tool_node)\n",
    "\n",
    "# Set entry point\n",
    "rag_workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edge\n",
    "rag_workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"end\": END}\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent\n",
    "rag_workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "rag_agent = rag_workflow.compile()\n",
    "\n",
    "print(\"Agentic RAG built from scratch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cell-46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the RAG agent\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(rag_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph image: {e}\")\n",
    "    print(\"\\nGraph structure:\")\n",
    "    print(rag_agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cell-47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Agentic RAG (with Anthropic Claude):\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "==================================================\n",
      "## DETAILED TOOL CALL SUMMARY\n",
      "\n",
      "Here's a comprehensive breakdown of each tool call I made, the inputs used, and the reasoning behind them:\n",
      "\n",
      "---\n",
      "\n",
      "### **Tool Call #1**\n",
      "- **Function:** `search_investment_knowledge`\n",
      "- **Input:** `\"Stone Ridge investment philosophy approach strategy\"`\n",
      "- **Why:** This was my initial broad search to directly answer your question about Stone Ridge's investment philosophy. I used general terms that would likely appear in any discussion of their core approach.\n",
      "- **Result:** Returned mostly disclaimer language, not substantive content about their philosophy.\n",
      "\n",
      "### **Tool Call #2**\n",
      "- **Function:** `search_investment_knowledge`\n",
      "- **Input:** `\"investment philosophy core principles reinsurance alternative investments\"`\n",
      "- **Why:** Since the first search didn't yield good results, I refined to include specific business areas (reinsurance, alternative investments) that Stone Ridge is known for, hoping to find philosophy discussions in that context.\n",
      "- **Result:** Found some information about legacy reinsurance and their approach to quota shares and Bayesian methods.\n",
      "\n",
      "### **Tool Call #3**\n",
      "- **Function:** `search_investment_knowledge`\n",
      "- **Input:** `\"Stone Ridge philosophy Bayesian approach risk management diversification\"`\n",
      "- **Why:** The previous search mentioned \"Bayesian\" methods, which seemed important to their philosophy. I searched specifically for this term along with risk management concepts.\n",
      "- **Result:** Found more about their Bayesian approach and \"being less wrong\" philosophy.\n",
      "\n",
      "### **Tool Call #4**\n",
      "- **Function:** `search_investment_knowledge`\n",
      "- **Input:** `\"alternative investments strategy uncorrelated returns portfolio construction\"`\n",
      "- **Why:** I wanted to understand their broader portfolio strategy and how they think about constructing investments across different asset classes.\n",
      "- **Result:** Mostly returned disclaimer language again.\n",
      "\n",
      "### **Tool Call #5**\n",
      "- **Function:** `search_investment_knowledge`\n",
      "- **Input:** `\"Stone Ridge business model value creation long-term thinking patient capital\"`\n",
      "- **Why:** I shifted to search for their business model and value creation approach, thinking this would reveal philosophical underpinnings.\n",
      "- **Result:** **JACKPOT!** Found key statement: \"At Stone Ridge, we relentlessly focus on growing after-tax cash flow to drive durable equity value in our operating businesses\" and mentions of their approach to learning and updating.\n",
      "\n",
      "### **Tool Call #6**\n",
      "- **Function:** `search_investment_knowledge`\n",
      "- **Input:** `\"thinking deeply open-mindedness posterior updating conviction less wrong\"`\n",
      "- **Why:** The previous search mentioned these specific concepts. I searched for these exact phrases to find more detailed explanations of their philosophical approach.\n",
      "- **Result:** Found excellent content about confirmation bias, Bayesian updating, and their philosophy of \"being less wrong.\"\n",
      "\n",
      "### **Tool Call #7**\n",
      "- **Function:** `search_investment_knowledge`\n",
      "- **Input:** `\"Stone Ridge approach adaptive learning Bayesian Fisher egoless practice\"`\n",
      "- **Why:** The previous results mentioned \"Bayesian Fisher\" and being \"less wrong.\" I wanted to understand this reference and their learning philosophy more deeply.\n",
      "- **Result:** Found the Mel Fisher treasure hunting story and how it relates to their Bayesian approach - a key metaphor for their philosophy.\n",
      "\n",
      "### **Tool Call #8**\n",
      "- **Function:** `search_investment_knowledge`\n",
      "- **Input:** `\"reinsurance oil and gas structured products asset-backed securities investment areas\"`\n",
      "- **Why:** To understand the specific investment areas where they apply their philosophy and provide concrete examples.\n",
      "- **Result:** Found information about their reinsurance business, quota shares, and legacy reinsurance approach.\n",
      "\n",
      "---\n",
      "\n",
      "## **STONE RIDGE'S INVESTMENT PHILOSOPHY**\n",
      "\n",
      "Based on my comprehensive search of the knowledge base, here's what I found about Stone Ridge's investment philosophy:\n",
      "\n",
      "### **Core Philosophy: Bayesian Thinking and \"Being Less Wrong\"**\n",
      "\n",
      "Stone Ridge's investment philosophy is fundamentally rooted in **Bayesian statistics and adaptive learning**. They describe their approach as \"a beautiful, egoless, daily practice of being less wrong.\" Key principles include:\n",
      "\n",
      "1. **Continuous Learning and Updating**: They emphasize \"thinking deeply about what we know before we know, open-mindedness to ‚Äì and hunger for ‚Äì new data, and extremely rapid posterior updating.\"\n",
      "\n",
      "2. **Avoiding Confirmation Bias**: As they state: \"Confirmation bias is the worst enemy of iteration. In a Bayesian system, it's fatal. If you only accept the data that supports your hypothesis, you're not updating ‚Äì you're entrenching.\"\n",
      "\n",
      "3. **Humility and Adaptability**: \"Success is not always linked to intelligence, boldness, or experience, but does consistently follow those most adaptive.\" They believe in having \"the humility to trade conviction for information, one update at a time.\"\n",
      "\n",
      "4. **The Mel Fisher Metaphor**: They reference treasure hunter Mel Fisher as an exemplar of Bayesian thinking - someone who updated his beliefs daily based on new data, becoming \"less wrong\" each day until finding the treasure.\n",
      "\n",
      "### **Business Focus: After-Tax Cash Flow and Durable Value**\n",
      "\n",
      "\"At Stone Ridge, we relentlessly focus on **growing after-tax cash flow to drive durable equity value in our operating businesses**.\"\n",
      "\n",
      "### **Investment Approach in Practice**\n",
      "\n",
      "In **reinsurance**, they pursue:\n",
      "- **Prospective quota shares**: \"Aligned, partnership trades in which Stone Ridge shares risk pro rata with leading reinsurers, tapping into their masterful Bayesian updating cycle management skills across dozens of lines of business\"\n",
      "- **Selective legacy reinsurance**: They're cautious about legacy-only strategies due to confirmation bias risks, but selectively pursue attractive opportunities\n",
      "\n",
      "Their **Longtail Re** business (started in 2020) focuses on:\n",
      "1. Partnering with the world's best underwriters to generate hyper-diversified casualty liabilities that deliver low-cost float\n",
      "2. Investing that float in proprietary Stone Ridge-generated fixed income assets with superior risk-adjusted expected returns\n",
      "\n",
      "### **Cultural Values**\n",
      "\n",
      "- \"We would rather look dumb by asking, than not ask and be dumb\"\n",
      "- Daily self-reflection: \"Was I less wrong today?\"\n",
      "- Courage to create with conviction when they believe they have an edge\n",
      "\n",
      "---\n",
      "\n",
      "**Please note:** This information is for educational purposes only and does not constitute investment advice. Any investment decisions should be made in consultation with qualified advisors and based on definitive offering documents.\n",
      "\n",
      "*As a porcupine assistant, I hope this thorough breakdown of my search process and findings helps you understand both Stone Ridge's philosophy and how I gathered this information!* ü¶î\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG agent\n",
    "print(\"Testing Agentic RAG (with Anthropic Claude):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is Stone Ridge's investment philosophy? INCLUDE DETAILS ABOUT EACH TOOL CALL YOU MADE, THE INPUT, AND WHY\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cell-48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with complex query:\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "==================================================\n",
      "Based on the Stone Ridge knowledge base, here's what they say about their energy investments:\n",
      "\n",
      "## Energy Investments\n",
      "\n",
      "Stone Ridge launched their energy franchise almost five years ago (from the time of the letter). They share some important lessons learned:\n",
      "\n",
      "1. **Initial Approach**: They initially believed that their financial sophistication, proprietary financing, and hedging technology - along with their material edge in cost of funds - would be sufficient for best-in-class investment performance.\n",
      "\n",
      "2. **Key Learning**: They \"quickly and painfully learned\" that **financial sophistication cannot substitute for industrial control**. In energy markets, **physics ‚Äì not finance ‚Äì sets the tuition entrepreneurs must pay**.\n",
      "\n",
      "3. **Strategic Pivot**: After this realization, they partnered with **Flywheel Energy**, which they describe as \"by far the best operators\" in the space. This suggests they recognized the importance of operational excellence and industrial expertise in energy investing.\n",
      "\n",
      "4. **Philosophy**: They reference the idea of going \"a little further than others\" to get closer to what is knowable, noting that \"there's gold oil and gas in them thar hills. It is waiting.\"\n",
      "\n",
      "The key takeaway is Stone Ridge's emphasis on the importance of operational expertise and industrial control in energy investments, rather than relying solely on financial engineering.\n",
      "\n",
      "## Your Calculation\n",
      "\n",
      "If Stone Ridge invested $100 million with a 50% annual return, the total after 1 year would be **$150 million**.\n",
      "\n",
      "---\n",
      "*Please note: This information is for educational purposes only and should not be considered investment advice.*\n"
     ]
    }
   ],
   "source": [
    "# Test with a complex query requiring both RAG and calculation\n",
    "print(\"Testing with complex query:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(\n",
    "        content=\"What does Stone Ridge say about their energy investments? Also, if they invested $100 million with a 50% annual return, what would be the total after 1 year?\"\n",
    "    )]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cell-49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent decision-making (should NOT use RAG):\n",
      "==================================================\n",
      "\n",
      "Final Response:\n",
      "125 * 8 = **1,000**\n"
     ]
    }
   ],
   "source": [
    "# Test that the agent knows when NOT to use RAG\n",
    "print(\"Testing agent decision-making (should NOT use RAG):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is 125 * 8?\")]\n",
    "})\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-52",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #3:\n",
    "\n",
    "Compare the experience of building an agent from scratch with LangGraph versus using `create_agent` from Module 3. What are the trade-offs between control and convenience? When would you choose one approach over the other for a Stone Ridge investment assistant?\n",
    "\n",
    "##### Answer:\n",
    "LangGraph gives you total control at the expense of convenience.\n",
    "\n",
    "I would gladly choose LangChain's create_agent abstraction for the investment assistant. From my limited exposure to both, I would choose create_agent for almost any general-purpose agent use case. LangChain's create_agent gives me everything I would want‚Äîa solid abstraction, middleware to hook into the control flow and modify behavior, out-of-the-box telemetry, tool use error handling, and even the ability to manipulate\n",
    "state (e.g., customize compaction at various points). So while LangChain is a higher-level abstraction, from what I can tell, it is still very flexible.\n",
    "\n",
    "I could see LangGraph being useful for use cases where you want less of a \"general-purpose\" agent and more determinism in the control flow‚Äîe.g., task-specific agents where the high level workflow is already well defined. For example, if there is a workflow with several defined steps, then LangGraph would be a good way to orchestrate the control flow: always do X, then Y, then Z (where X, Y, and/or Z solve some goals agentically). LangGraph also gives full control, so you could implement any type of workflow you wanted‚Äîthe limiting factor for me personally is imagination. I'm having a tough time thinking of many concrete use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-53",
   "metadata": {},
   "source": [
    "## ‚ùì Question #4:\n",
    "\n",
    "We used Anthropic Claude for reasoning and HuggingFace for embeddings. What are the considerations when choosing different providers for different tasks in an AI application? How might these choices impact a production investment assistant?\n",
    "\n",
    "##### Answer:\n",
    "There are several considerations when choosing providers for different tasks in an AI application, primarily cost and performance. Cost is easily measurable, and performance is somewhat subjective for comparable classes of models (unless the performance gap is large, then it's obvious).\n",
    "\n",
    "For agentic workloads, I have to imagine that the only real options that can reason through complex problems are the frontier models from OpenAI, Anthropic, and Google. With unlimited time, it would be beneficial to test specific use cases against all three model providers and try to qualitatively measure outcomes. If there is no discernible difference, use the cheaper model. If there is a difference, then it's a cost/benefit question.\n",
    "\n",
    "The same goes for embedding models. HuggingFace provides free models. Are the OpenAI embedding models so much better that they're worth the cost? That would have to be \"quantified\" for specific use cases (\"quantified\" is in quotes because, for many use cases, the quality of the result will be subjective).\n",
    "\n",
    "These choices would impact a production investment assistant dramatically‚Äîa poor reasoning model won't be able to navigate to the correct data, and a poor embedding model might return worse information. In this exercise, I used a high-quality reasoning model (Claude Sonnet 4.5) with a poor man's embedding model (a low-dimension HuggingFace model). The agent had to perform TEN tool calls before it was satisfied. A worse reasoning model may not have been able to handle the lackluster tool call results and navigate to the correct space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #2: Extend the Agent with Memory\n",
    "\n",
    "LangGraph supports **checkpointing** which enables conversation memory across invocations.\n",
    "\n",
    "Your task: Add memory to the RAG agent so it can:\n",
    "1. Remember previous questions in the conversation\n",
    "2. Reference past context when answering new questions\n",
    "3. Build on previous answers\n",
    "\n",
    "Hint: Use `MemorySaver` from `langgraph.checkpoint.memory` and pass a `thread_id` in the config.\n",
    "\n",
    "**üìö Documentation:**\n",
    "- [LangGraph Persistence & Memory](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "- [How to add memory to your graph](https://langchain-ai.github.io/langgraph/how-tos/persistence/)\n",
    "- [MemorySaver Reference](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Create a memory saver\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Recompile the agent with checkpointing\n",
    "rag_agent_with_memory = rag_workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Test with a conversation that requires memory\n",
    "# Use \n",
    "\n",
    "config={\"configurable\": {\"thread_id\": \"conversation-1\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cell-56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the knowledge base, here's Stone Ridge's investment philosophy in 17 words:\n",
      "\n",
      "**Relentlessly focus on growing after-tax cash flow to drive durable equity value through conviction-based operating businesses.**\n",
      "\n",
      "This philosophy emphasizes deep thinking, open-mindedness to new data, rapid updating, and courageous conviction-based decision-making.\n",
      "Stone Ridge could breed porcupines as operating businesses, relentlessly focusing on after-tax quill sales cash flow. Through conviction-based husbandry, rapid adaptation to market data, and courageous expansion, they'd drive durable equity value.\n",
      "I'm a porcupine helping with investments‚Äîfeeling sharp and slightly prickly!\n",
      "You sent me 4 messages.\n",
      "\n",
      "**Five-word summary: Philosophy, porcupines, feelings, conversation recap.**\n"
     ]
    }
   ],
   "source": [
    "# Test your memory-enabled agent with a multi-turn conversation\n",
    "\n",
    "response = rag_agent_with_memory.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"What is Stone Ridge's investment philosophy? Summarize in 17 words.\")]},\n",
    "    config=config\n",
    ")\n",
    "print(response[\"messages\"][-1].content)\n",
    "\n",
    "response = rag_agent_with_memory.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"Based entirely on your previous answer, explain how Stone Ridge could make money off porcupines. Be sure to include the spirit of the previous answer in your response. Answer in 34 words.\")]},\n",
    "    config=config\n",
    ")\n",
    "print(response[\"messages\"][-1].content)\n",
    "\n",
    "response = rag_agent_with_memory.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"Now in 10 words tell me how you really feel.\")]},\n",
    "    config=config\n",
    ")\n",
    "print(response[\"messages\"][-1].content)\n",
    "\n",
    "response = rag_agent_with_memory.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"Tell me how many messages I sent you and summarize our entire conversation in 5 words.\")]},\n",
    "    config=config\n",
    ")\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89bca5",
   "metadata": {},
   "source": [
    "# Human-In-The-Loop Bonus Question\n",
    "\n",
    "### How it works\n",
    "\n",
    "#### Enable checkpointing so that we can resume \n",
    "```python\n",
    "memory = MemorySaver()\n",
    "rag_workflow.compile(\n",
    "    checkpointer=memory,\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "#### Interupt before all tool calls\n",
    "```python\n",
    "rag_workflow.compile(\n",
    "    ...\n",
    "    interrupt_before=[\"tools\"]\n",
    ")\n",
    "```\n",
    "\n",
    "#### Send an initial message in\n",
    "```python\n",
    "result = rag_agent_with_interrupt.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is Stone Ridge's philosophy?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"conversation-2\"}}\n",
    ")\n",
    "```\n",
    "\n",
    "#### Loop until not interrupted (last message is not tool calls)\n",
    "```python\n",
    "while(result[\"messages\"][-1].tool_calls):\n",
    "```\n",
    "\n",
    "#### Prompt for approval for all tool calls\n",
    "```python\n",
    "        approved = prompt_tool_approval(tc['name'], tc['args'])\n",
    "```\n",
    "\n",
    "#### If approved, continue with no new message (will continue to execute tool)\n",
    "```python\n",
    "        if approved:\n",
    "            # Resume normally - execute the tools\n",
    "            result = rag_agent_with_interrupt.invoke(None, {\"configurable\": {\"thread_id\": \"conversation-2\"}})\n",
    "```\n",
    "\n",
    "#### If rejected, pass in a tool call result with error status and a message telling the LLM that it was rejected\n",
    "```python\n",
    "    result = rag_agent_with_interrupt.invoke(\n",
    "        {\"messages\": [ToolMessage(tool_call_id=tc['id'], status=\"error\", content=\"<system>THE USER REJECTED THIS TOOL INVOCATION. ASK THE USER HOW TO PROCEED.</system>\")]},\n",
    "        {\"configurable\": {\"thread_id\": \"conversation-2\"}}\n",
    "    )\n",
    "```\n",
    "\n",
    "#### One way or the other, it will eventually return a final result\n",
    "```python\n",
    "print(\"FINAL ANSWER: \" + result[\"messages\"][-1].content)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "524bed37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL ANSWER: I apologize for the technical difficulty. It seems I'm unable to access the knowledge base at the moment. \n",
      "\n",
      "Could you please let me know if you'd like me to:\n",
      "1. Try searching again\n",
      "2. Provide general information about what investment philosophies typically encompass\n",
      "3. Help you with something else\n",
      "\n",
      "I want to make sure I can best assist you with your question about Stone Ridge's investment philosophy.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "def prompt_tool_approval(tool_name: str, tool_input: dict) -> bool:\n",
    "    response = input(f\"\"\"\n",
    "        üîß TOOL APPROVAL REQUIRED\n",
    "        Tool:  {tool_name}\n",
    "        Args: {tool_input}\n",
    "        APPROVE (Y/N)?\n",
    "    \"\"\").strip().lower()\n",
    "\n",
    "    if response in ('y', 'yes'):\n",
    "        return True\n",
    "    elif response in ('n', 'no'):\n",
    "        return False\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "rag_agent_with_interrupt = rag_workflow.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"tools\"]\n",
    ")\n",
    "\n",
    "result = rag_agent_with_interrupt.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is Stone Ridge's philosophy?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"conversation-2\"}}\n",
    ")\n",
    "\n",
    "while(result[\"messages\"][-1].tool_calls):\n",
    "\n",
    "    last_message = result[\"messages\"][-1]\n",
    "    for tc in last_message.tool_calls:\n",
    "        approved = prompt_tool_approval(tc['name'], tc['args'])\n",
    "\n",
    "        if approved:\n",
    "            # Resume normally - execute the tools\n",
    "            result = rag_agent_with_interrupt.invoke(None, {\"configurable\": {\"thread_id\": \"conversation-2\"}})\n",
    "        else:\n",
    "            result = rag_agent_with_interrupt.invoke(\n",
    "                {\"messages\": [ToolMessage(tool_call_id=tc['id'], status=\"error\", content=\"<system>THE USER REJECTED THIS TOOL INVOCATION. ASK THE USER HOW TO PROCEED.</system>\")]},\n",
    "                {\"configurable\": {\"thread_id\": \"conversation-2\"}}\n",
    "            )\n",
    "\n",
    "print(\"FINAL ANSWER: \" + result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-57",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this module, we:\n",
    "\n",
    "1. **Built agents from scratch** using LangGraph's low-level primitives (StateGraph, nodes, edges)\n",
    "2. **Used Anthropic Claude** for powerful reasoning and generation\n",
    "3. **Transitioned to LangChain** for document loading and text splitting\n",
    "4. **Set up observability** with Arize Phoenix tracing\n",
    "5. **Created an Agentic RAG system** for Stone Ridge investor letters that intelligently decides when to retrieve information\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **StateGraph** gives you full control over agent architecture\n",
    "- **Conditional edges** enable dynamic routing based on LLM decisions\n",
    "- **Anthropic Claude** provides excellent reasoning for financial document analysis\n",
    "- **Phoenix** provides crucial visibility regardless of where your models run\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Now that you understand the fundamentals, you can:\n",
    "- Add more sophisticated routing logic\n",
    "- Implement human-in-the-loop patterns for investment decisions\n",
    "- Build multi-agent systems for complex analysis\n",
    "- Deploy to production with LangGraph Platform\n",
    "\n",
    "**üìö Further Reading:**\n",
    "- [LangGraph How-To Guides](https://langchain-ai.github.io/langgraph/how-tos/)\n",
    "- [Human-in-the-Loop Patterns](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)\n",
    "- [Multi-Agent Architectures](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)\n",
    "- [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)\n",
    "- [Anthropic Claude Documentation](https://docs.anthropic.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "04-agentic-rag-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
